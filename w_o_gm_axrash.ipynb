{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset into a pandas dataframe\n",
        "df = pd.read_csv('ADSXLIST_07Sep2023.csv')\n",
        "\n",
        "common_features = ['AXRASH', 'AXMUSCLE', 'AXURNFRQ', 'AXENERGY', 'AXDROWSY', 'AXDIZZY', 'AXBREATH', 'AXCOUGH']\n",
        "\n",
        "# Define categorical features for one-hot encoding\n",
        "categorical_features = ['VISCODE', 'VISCODE2', 'SITEID']\n",
        "df = pd.get_dummies(df, columns=categorical_features)\n",
        "\n",
        "# Exclude any non-numeric columns (e.g., dates or other string columns)\n",
        "numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "# Ensure 'Phase' (target variable) is not in the features list\n",
        "if 'Phase' in numeric_columns:\n",
        "    numeric_columns.remove('Phase')\n",
        "\n",
        "# Define the number of iterations and splits\n",
        "num_iterations = 10\n",
        "num_splits = 6\n",
        "\n",
        "# Lists to store global accuracy and precision for each iteration\n",
        "global_accuracy_all_iterations = []\n",
        "global_precision_all_iterations = []\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    # Shuffle the data randomly for each iteration\n",
        "    df_shuffled = df.sample(frac=1, random_state=iteration * 123)\n",
        "\n",
        "    # Initial Splitting of the data into sections\n",
        "    split_size = len(df_shuffled) // num_splits\n",
        "    data_splits = [df_shuffled.iloc[i * split_size: (i + 1) * split_size] for i in range(num_splits)]\n",
        "\n",
        "    # Data Shifting: Move 25% data from each node to the next\n",
        "    for i in range(num_splits):\n",
        "        next_index = (i + 1) % num_splits\n",
        "        data_to_shift = data_splits[i].sample(frac=0.25, random_state=iteration)\n",
        "        data_splits[i] = data_splits[i].drop(data_to_shift.index)\n",
        "        data_splits[next_index] = pd.concat([data_splits[next_index], data_to_shift])\n",
        "\n",
        "    coefficients_list = []\n",
        "    intercepts_list = []\n",
        "\n",
        "    # Train local models and collect their parameters\n",
        "    for i in range(num_splits):\n",
        "        split_data = data_splits[i]\n",
        "\n",
        "        # Filter the 'AXRASH' data for Nodes 1 and 2\n",
        "        if i == 0:  # Node 1\n",
        "            split_data = split_data[split_data['AXRASH'] == 1]\n",
        "            features = ['AXRASH']\n",
        "        elif i == 1:  # Node 2\n",
        "            split_data = split_data[split_data['AXRASH'] == 2]\n",
        "            features = ['AXRASH']\n",
        "        else:  # Nodes 3 to 6\n",
        "            features = common_features\n",
        "\n",
        "        X = split_data[numeric_columns].copy()\n",
        "        y = split_data['Phase'].copy()\n",
        "\n",
        "        # Data preprocessing steps\n",
        "        X.fillna(0, inplace=True)\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=359)\n",
        "\n",
        "        model = LogisticRegression(max_iter=1000)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        coefficients_list.append(model.coef_)\n",
        "        intercepts_list.append(model.intercept_)\n",
        "\n",
        "    # Federated Averaging: Calculate mean of coefficients and intercepts\n",
        "    avg_coefficients = np.mean(coefficients_list, axis=0)\n",
        "    avg_intercepts = np.mean(intercepts_list, axis=0)\n",
        "\n",
        "    global_model = LogisticRegression(max_iter=1000)\n",
        "    global_model.coef_ = avg_coefficients\n",
        "    global_model.intercept_ = avg_intercepts\n",
        "\n",
        "    # Fit the global model on a small but representative subset of data to initialize 'classes_'\n",
        "    subset = df_shuffled.drop_duplicates(subset='Phase').head(10)\n",
        "    subset_X = subset[features].copy()\n",
        "    subset_X.fillna(0, inplace=True)\n",
        "    subset_y = subset['Phase'].copy()\n",
        "    global_model.fit(subset_X, subset_y)\n",
        "\n",
        "    # Evaluate the global model on each node's data, excluding nodes 1 and 2, and store the results\n",
        "    iteration_global_accuracy = []\n",
        "    iteration_global_precision = []\n",
        "\n",
        "    for i in range(num_splits):\n",
        "        if i == 0 or i == 1:  # Skip evaluation for nodes 1 and 2\n",
        "            continue\n",
        "\n",
        "        split_data = data_splits[i]\n",
        "        X = split_data[features].copy()\n",
        "        y = split_data['Phase'].copy()\n",
        "\n",
        "        # Data preprocessing\n",
        "        X.fillna(0, inplace=True)\n",
        "\n",
        "        y_pred = global_model.predict(X)\n",
        "        iteration_global_accuracy.append(accuracy_score(y, y_pred))\n",
        "        iteration_global_precision.append(precision_score(y, y_pred, average='weighted', zero_division=0))\n",
        "\n",
        "    # Store global accuracy and precision for this iteration\n",
        "    global_accuracy_all_iterations.append(iteration_global_accuracy)\n",
        "    global_precision_all_iterations.append(iteration_global_precision)\n",
        "\n",
        "# Organize the results into a DataFrame\n",
        "results_df = pd.DataFrame({\n",
        "    'Global Accuracy': global_accuracy_all_iterations,\n",
        "    'Global Precision': global_precision_all_iterations\n",
        "})\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results_df.to_csv('model_resultsg.csv', index=False)\n",
        "\n",
        "print(\"Results saved to 'model_resultsg.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSWbYGAoA_4D",
        "outputId": "567ac22a-369d-46e5-fb84-cd1f8c8c770d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to 'model_resultsg.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qccqktcfoj7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset into a pandas dataframe\n",
        "df = pd.read_csv('ADSXLIST_07Sep2023.csv')\n",
        "\n",
        "common_features = ['AXRASH', 'AXMUSCLE', 'AXURNFRQ', 'AXENERGY', 'AXDROWSY', 'AXDIZZY', 'AXBREATH', 'AXCOUGH']\n",
        "\n",
        "# Define categorical features for one-hot encoding\n",
        "categorical_features = ['VISCODE', 'VISCODE2', 'SITEID']\n",
        "df = pd.get_dummies(df, columns=categorical_features)\n",
        "\n",
        "# Exclude any non-numeric columns (e.g., dates or other string columns)\n",
        "numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "# Ensure 'Phase' (target variable) is not in the features list\n",
        "if 'Phase' in numeric_columns:\n",
        "    numeric_columns.remove('Phase')\n",
        "\n",
        "# Define the number of iterations and splits\n",
        "num_iterations = 10\n",
        "num_splits = 6\n",
        "\n",
        "# Lists to store global accuracy and precision for each iteration\n",
        "global_accuracy_all_iterations = []\n",
        "global_precision_all_iterations = []\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    df_shuffled = df.sample(frac=1, random_state=iteration * 123)\n",
        "\n",
        "    split_size = len(df_shuffled) // num_splits\n",
        "    data_splits = [df_shuffled.iloc[i * split_size: (i + 1) * split_size] for i in range(num_splits)]\n",
        "\n",
        "    for i in range(num_splits):\n",
        "        next_index = (i + 1) % num_splits\n",
        "        data_to_shift = data_splits[i].sample(frac=0.25, random_state=iteration)\n",
        "        data_splits[i] = data_splits[i].drop(data_to_shift.index)\n",
        "        data_splits[next_index] = pd.concat([data_splits[next_index], data_to_shift])\n",
        "\n",
        "    coefficients_list = []\n",
        "    intercepts_list = []\n",
        "\n",
        "    for i in range(num_splits):\n",
        "        split_data = data_splits[i]\n",
        "\n",
        "        if i in [0, 1]:  # Node 1 and Node 2\n",
        "            split_data = split_data[split_data['AXRASH'] == (i + 1)]\n",
        "            features = ['AXRASH']\n",
        "        else:  # Nodes 3 to 6\n",
        "            features = common_features\n",
        "\n",
        "        X = split_data[numeric_columns].copy()\n",
        "        y = split_data['Phase'].copy()\n",
        "\n",
        "        X.fillna(0, inplace=True)\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=359)\n",
        "\n",
        "        model = LogisticRegression(max_iter=1000)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        coefficients_list.append(model.coef_)\n",
        "        intercepts_list.append(model.intercept_)\n",
        "\n",
        "    avg_coefficients = np.mean(coefficients_list, axis=0)\n",
        "    avg_intercepts = np.mean(intercepts_list, axis=0)\n",
        "\n",
        "    global_model = LogisticRegression(max_iter=1000)\n",
        "    global_model.coef_ = avg_coefficients\n",
        "    global_model.intercept_ = avg_intercepts\n",
        "\n",
        "    # Fit the global model on a small but representative subset of data\n",
        "    subset = df_shuffled.drop_duplicates(subset='Phase').head(10)\n",
        "    subset_X = subset[numeric_columns].copy()\n",
        "    subset_X.fillna(0, inplace=True)\n",
        "    subset_y = subset['Phase'].copy()\n",
        "    global_model.fit(subset_X, subset_y)\n",
        "\n",
        "    # Evaluate the global model on each node's data, excluding nodes 1 and 2, and store the results\n",
        "    iteration_global_accuracy = []\n",
        "    iteration_global_precision = []\n",
        "\n",
        "    for i in range(2, num_splits):\n",
        "        split_data = data_splits[i]\n",
        "        X = split_data[numeric_columns].copy()\n",
        "        y = split_data['Phase'].copy()\n",
        "\n",
        "        X.fillna(0, inplace=True)\n",
        "\n",
        "        y_pred = global_model.predict(X)\n",
        "        iteration_global_accuracy.append(accuracy_score(y, y_pred))\n",
        "        iteration_global_precision.append(precision_score(y, y_pred, average='weighted', zero_division=0))\n",
        "\n",
        "    # Additional evaluation for Node 1 and Node 2\n",
        "    for i in range(2):\n",
        "        node_data = df[df['AXRASH'] == i + 1]\n",
        "        X_node = node_data[numeric_columns].copy()\n",
        "        y_node = node_data['Phase'].copy()\n",
        "\n",
        "        X_node.fillna(0, inplace=True)\n",
        "        y_pred_node = global_model.predict(X_node)\n",
        "\n",
        "        accuracy_node = accuracy_score(y_node, y_pred_node)\n",
        "        precision_node = precision_score(y_node, y_pred_node, average='weighted', zero_division=0)\n",
        "\n",
        "        # Store the results for Node 1 and Node 2\n",
        "        if i == 0:\n",
        "            iteration_global_accuracy.insert(i, accuracy_node)\n",
        "            iteration_global_precision.insert(i, precision_node)\n",
        "        else:\n",
        "            iteration_global_accuracy.append(accuracy_node)\n",
        "            iteration_global_precision.append(precision_node)\n",
        "\n",
        "    global_accuracy_all_iterations.append(iteration_global_accuracy)\n",
        "    global_precision_all_iterations.append(iteration_global_precision)\n",
        "\n",
        "# Organize the results into a DataFrame\n",
        "results_df = pd.DataFrame({\n",
        "    'Global Accuracy': global_accuracy_all_iterations,\n",
        "    'Global Precision': global_precision_all_iterations\n",
        "})\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results_df.to_csv('model_resultsg1.csv', index=False)\n",
        "\n",
        "print(\"Results saved to 'model_resultsg1.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSduwiXXIOL_",
        "outputId": "f1c8535b-6d6f-485d-c41b-f4cd0eeb3537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to 'model_resultsg1.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset into a pandas dataframe\n",
        "df = pd.read_csv('ADSXLIST_07Sep2023.csv')\n",
        "\n",
        "common_features = ['AXRASH', 'AXMUSCLE', 'AXURNFRQ', 'AXENERGY', 'AXDROWSY', 'AXDIZZY', 'AXBREATH', 'AXCOUGH']\n",
        "\n",
        "# Define categorical features for one-hot encoding\n",
        "categorical_features = ['VISCODE', 'VISCODE2', 'SITEID']\n",
        "df = pd.get_dummies(df, columns=categorical_features)\n",
        "\n",
        "# Exclude any non-numeric columns (e.g., dates or other string columns)\n",
        "numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "# Ensure 'Phase' (target variable) is not in the features list\n",
        "if 'Phase' in numeric_columns:\n",
        "    numeric_columns.remove('Phase')\n",
        "\n",
        "# Define the number of iterations and splits\n",
        "num_iterations = 10\n",
        "num_splits = 6\n",
        "\n",
        "# Lists to store global accuracy and precision for Node 1 and Node 2 for each iteration\n",
        "global_accuracy_node_1_2 = []\n",
        "global_precision_node_1_2 = []\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    df_shuffled = df.sample(frac=1, random_state=iteration * 123)\n",
        "\n",
        "    split_size = len(df_shuffled) // num_splits\n",
        "    data_splits = [df_shuffled.iloc[i * split_size: (i + 1) * split_size] for i in range(num_splits)]\n",
        "\n",
        "    for i in range(num_splits):\n",
        "        next_index = (i + 1) % num_splits\n",
        "        data_to_shift = data_splits[i].sample(frac=0.25, random_state=iteration)\n",
        "        data_splits[i] = data_splits[i].drop(data_to_shift.index)\n",
        "        data_splits[next_index] = pd.concat([data_splits[next_index], data_to_shift])\n",
        "\n",
        "    coefficients_list = []\n",
        "    intercepts_list = []\n",
        "\n",
        "    for i in range(num_splits):\n",
        "        split_data = data_splits[i]\n",
        "\n",
        "        if i in [0, 1]:  # Node 1 and Node 2\n",
        "            split_data = split_data[split_data['AXRASH'] == (i + 1)]\n",
        "            features = ['AXRASH']\n",
        "        else:  # Nodes 3 to 6\n",
        "            features = common_features\n",
        "\n",
        "        X = split_data[numeric_columns].copy()\n",
        "        y = split_data['Phase'].copy()\n",
        "\n",
        "        X.fillna(0, inplace=True)\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=359)\n",
        "\n",
        "        model = LogisticRegression(max_iter=1000)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        coefficients_list.append(model.coef_)\n",
        "        intercepts_list.append(model.intercept_)\n",
        "\n",
        "    avg_coefficients = np.mean(coefficients_list, axis=0)\n",
        "    avg_intercepts = np.mean(intercepts_list, axis=0)\n",
        "\n",
        "    global_model = LogisticRegression(max_iter=1000)\n",
        "    global_model.coef_ = avg_coefficients\n",
        "    global_model.intercept_ = avg_intercepts\n",
        "\n",
        "    # Fit the global model on a small but representative subset of data\n",
        "    subset = df_shuffled.drop_duplicates(subset='Phase').head(10)\n",
        "    subset_X = subset[numeric_columns].copy()\n",
        "    subset_X.fillna(0, inplace=True)\n",
        "    subset_y = subset['Phase'].copy()\n",
        "    global_model.fit(subset_X, subset_y)\n",
        "\n",
        "    # Evaluate the global model only for Node 1 and Node 2\n",
        "    accuracy_precision_node_1_2 = []\n",
        "\n",
        "    for i in range(2):\n",
        "        node_data = df[df['AXRASH'] == i + 1]\n",
        "        X_node = node_data[numeric_columns].copy()\n",
        "        y_node = node_data['Phase'].copy()\n",
        "\n",
        "        X_node.fillna(0, inplace=True)\n",
        "        y_pred_node = global_model.predict(X_node)\n",
        "\n",
        "        accuracy_node = accuracy_score(y_node, y_pred_node)\n",
        "        precision_node = precision_score(y_node, y_pred_node, average='weighted', zero_division=0)\n",
        "\n",
        "        accuracy_precision_node_1_2.append((accuracy_node, precision_node))\n",
        "\n",
        "    global_accuracy_node_1_2.append(accuracy_precision_node_1_2[0][0])\n",
        "    global_precision_node_1_2.append(accuracy_precision_node_1_2[0][1])\n",
        "    global_accuracy_node_1_2.append(accuracy_precision_node_1_2[1][0])\n",
        "    global_precision_node_1_2.append(accuracy_precision_node_1_2[1][1])\n",
        "\n",
        "# Organize the results into a DataFrame\n",
        "results_df = pd.DataFrame({\n",
        "    'Node 1 Global Accuracy': global_accuracy_node_1_2[::2],  # Extracting even indices (Node 1)\n",
        "    'Node 1 Global Precision': global_precision_node_1_2[::2],\n",
        "    'Node 2 Global Accuracy': global_accuracy_node_1_2[1::2],  # Extracting odd indices (Node 2)\n",
        "    'Node 2 Global Precision': global_precision_node_1_2[1::2]\n",
        "})\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results_df.to_csv('model_results_nodes_1_2.csv', index=False)\n",
        "\n",
        "print(\"Results saved to 'model_results_nodes_1_2.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zjlLDfALdW5",
        "outputId": "85c8f65b-4d95-4bad-bcb0-e6fcacf7b30a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to 'model_results_nodes_1_2.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f0ZuCfcZIN9c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}