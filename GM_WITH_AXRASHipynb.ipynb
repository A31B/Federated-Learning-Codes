{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64i7Kefxvkej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97ab7c10-a65c-460e-e0e4-68fc50d37392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1  2 -1]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('ADSXLIST_07Sep2023.csv')\n",
        "\n",
        "# Display unique values in the 'AXRASH' column\n",
        "axrash_values = df['AXDIARRH'].unique()\n",
        "print(axrash_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('ADSXLIST_07Sep2023.csv')\n",
        "\n",
        "# Count the frequency of each unique value in the 'AXRASH' column\n",
        "axrash_value_counts = df['Phase'].value_counts()\n",
        "\n",
        "# Display the counts\n",
        "print(axrash_value_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J6Z1ttwzbkp",
        "outputId": "8904e760-b94c-49da-8e1f-1ef4b04d0f83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ADNI1     4201\n",
            "ADNIGO     683\n",
            "Name: Phase, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('ADSXLIST_07Sep2023.csv')\n",
        "\n",
        "# Display unique values in the 'AXVOMIT' column\n",
        "AXVOMIT_values = df['AXVOMIT'].unique()\n",
        "print(AXVOMIT_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZwcfGuyz7Jj",
        "outputId": "11ad3542-7809-4802-c4bd-9f11c28be590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1  2 -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('ADSXLIST_07Sep2023.csv')\n",
        "\n",
        "# Count the frequency of each unique value in the 'AXVOMIT' column\n",
        "AXVOMIT_value_counts = df['AXVOMIT'].value_counts()\n",
        "\n",
        "# Display the counts\n",
        "print(AXVOMIT_value_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4bJZHeA0LK4",
        "outputId": "a72af48c-f68d-49df-e214-ea65a556f14b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1    4808\n",
            " 2      67\n",
            "-1       9\n",
            "Name: AXVOMIT, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GbzyUztx1eZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset into a pandas dataframe\n",
        "df = pd.read_csv('ADSXLIST_07Sep2023.csv')\n",
        "\n",
        "# Define the number of iterations and splits\n",
        "num_iterations = 10\n",
        "num_splits = 6\n",
        "\n",
        "# Lists to store accuracy and precision for each iteration\n",
        "local_accuracy_all_iterations = []\n",
        "local_precision_all_iterations = []\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    # Shuffle the data randomly for each iteration\n",
        "    df_shuffled = df.sample(frac=1, random_state=iteration * 123)\n",
        "\n",
        "    # Initial Splitting of the data into sections\n",
        "    split_size = len(df_shuffled) // num_splits\n",
        "    data_splits = [df_shuffled.iloc[i * split_size: (i + 1) * split_size] for i in range(num_splits)]\n",
        "\n",
        "    # Data Shifting: Move 25% data from each node to the next\n",
        "    for i in range(num_splits):\n",
        "        next_index = (i + 1) % num_splits  # Circular shift\n",
        "        data_to_shift = data_splits[i].sample(frac=0.25, random_state=iteration)\n",
        "        data_splits[i] = data_splits[i].drop(data_to_shift.index)\n",
        "        data_splits[next_index] = pd.concat([data_splits[next_index], data_to_shift])\n",
        "\n",
        "    # Lists for storing local accuracy and precision\n",
        "    local_accuracy_iteration = []\n",
        "    local_precision_iteration = []\n",
        "\n",
        "    for i in range(num_splits):\n",
        "        split_data = data_splits[i]\n",
        "\n",
        "        # Filter the 'AXRASH' data for Nodes 1 and 2\n",
        "        if i == 0:  # Node 1\n",
        "            split_data = split_data[split_data['AXRASH'] == 1]\n",
        "            features = ['AXRASH']\n",
        "        elif i == 1:  # Node 2\n",
        "            split_data = split_data[split_data['AXRASH'] == 2]\n",
        "            features = ['AXRASH']\n",
        "        else:  # Nodes 3 to 6\n",
        "            features = ['AXRASH', 'AXVOMIT', 'AXDIARRH', 'AXCONSTP', 'AXABDOMN', 'AXSWEATN', 'VISCODE', 'VISCODE2', 'SITEID']\n",
        "\n",
        "        X = split_data[features].copy()\n",
        "        y = split_data['Phase'].copy()\n",
        "\n",
        "        # Data preprocessing steps\n",
        "        # Convert all categorical features using one-hot encoding\n",
        "        if 'VISCODE' in features or 'VISCODE2' in features or 'SITEID' in features:\n",
        "            X = pd.get_dummies(X, columns=['VISCODE', 'VISCODE2', 'SITEID'])\n",
        "\n",
        "        X.fillna(0, inplace=True)\n",
        "\n",
        "        full_features = ['AXRASH', 'AXVOMIT', 'AXDIARRH', 'AXCONSTP', 'AXABDOMN', 'AXSWEATN', 'VISCODE', 'VISCODE2', 'SITEID']\n",
        "        X = X.reindex(columns=full_features, fill_value=0)\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=359)\n",
        "\n",
        "        model = LogisticRegression(max_iter=1000)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        y_pred = model.predict(X_test)\n",
        "        local_accuracy_iteration.append(accuracy_score(y_test, y_pred))\n",
        "        local_precision_iteration.append(precision_score(y_test, y_pred, average='weighted', zero_division=0))\n",
        "\n",
        "    # Store results\n",
        "    local_accuracy_all_iterations.append(local_accuracy_iteration)\n",
        "    local_precision_all_iterations.append(local_precision_iteration)\n",
        "\n",
        "# Display and save the results\n",
        "# Organize the results into a DataFrame\n",
        "results_df = pd.DataFrame({\n",
        "    'Local Accuracy': local_accuracy_all_iterations,\n",
        "    'Local Precision': local_precision_all_iterations\n",
        "})\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results_df.to_csv('model_resultsl.csv', index=False)\n",
        "\n",
        "print(\"Results saved to 'model_resultsl.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEiAKTlQ1eWg",
        "outputId": "5e15c1e8-fa9b-4ec2-fe2d-6330eca0cfda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to 'model_resultsl.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset into a pandas dataframe\n",
        "df = pd.read_csv('ADSXLIST_07Sep2023.csv')\n",
        "\n",
        "common_features = ['AXRASH', 'AXVOMIT', 'AXDIARRH', 'AXCONSTP', 'AXABDOMN', 'AXSWEATN']\n",
        "# Define categorical features for one-hot encoding\n",
        "categorical_features = ['VISCODE', 'VISCODE2', 'SITEID']\n",
        "df = pd.get_dummies(df, columns=categorical_features)\n",
        "\n",
        "# Exclude any non-numeric columns (e.g., dates or other string columns)\n",
        "numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "# Ensure 'Phase' (target variable) is not in the features list\n",
        "if 'Phase' in numeric_columns:\n",
        "    numeric_columns.remove('Phase')\n",
        "\n",
        "# Define the number of iterations and splits\n",
        "num_iterations = 10\n",
        "num_splits = 6\n",
        "\n",
        "# Lists to store global accuracy and precision for each iteration\n",
        "global_accuracy_all_iterations = []\n",
        "global_precision_all_iterations = []\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    # Shuffle the data randomly for each iteration\n",
        "    df_shuffled = df.sample(frac=1, random_state=iteration * 123)\n",
        "\n",
        "    # Initial Splitting of the data into sections\n",
        "    split_size = len(df_shuffled) // num_splits\n",
        "    data_splits = [df_shuffled.iloc[i * split_size: (i + 1) * split_size] for i in range(num_splits)]\n",
        "\n",
        "    # Data Shifting: Move 25% data from each node to the next\n",
        "    for i in range(num_splits):\n",
        "        next_index = (i + 1) % num_splits\n",
        "        data_to_shift = data_splits[i].sample(frac=0.25, random_state=iteration)\n",
        "        data_splits[i] = data_splits[i].drop(data_to_shift.index)\n",
        "        data_splits[next_index] = pd.concat([data_splits[next_index], data_to_shift])\n",
        "\n",
        "    # Lists for storing model parameters\n",
        "    coefficients_list = []\n",
        "    intercepts_list = []\n",
        "\n",
        "    # Train local models and collect their parameters\n",
        "    for i in range(num_splits):\n",
        "        split_data = data_splits[i]\n",
        "        # Prepare the data for each node\n",
        "        if i == 0:\n",
        "            features = ['AXRASH'] if 'AXRASH' in df.columns else []\n",
        "        elif i == 1:\n",
        "            features = ['AXRASH'] if 'AXRASH' in df.columns else []\n",
        "        else:\n",
        "            features = common_features\n",
        "        X = split_data[numeric_columns].copy()\n",
        "        y = split_data['Phase'].copy()\n",
        "\n",
        "        # Data preprocessing steps\n",
        "        X.fillna(0, inplace=True)\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=359)\n",
        "\n",
        "        model = LogisticRegression(max_iter=1000)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        coefficients_list.append(model.coef_)\n",
        "        intercepts_list.append(model.intercept_)\n",
        "\n",
        "        y_pred = model.predict(X_test)\n",
        "        local_accuracy = accuracy_score(y_test, y_pred)\n",
        "        local_precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    # Federated Averaging: Calculate mean of coefficients and intercepts\n",
        "    avg_coefficients = np.mean(coefficients_list, axis=0)\n",
        "    avg_intercepts = np.mean(intercepts_list, axis=0)\n",
        "\n",
        "    global_model = LogisticRegression(max_iter=1000)\n",
        "    global_model.coef_ = avg_coefficients\n",
        "    global_model.intercept_ = avg_intercepts\n",
        "\n",
        "    # Fit the global model on a small but representative subset of data to initialize 'classes_'\n",
        "    subset = df_shuffled.drop_duplicates(subset='Phase').head(10)\n",
        "    subset_X = subset[numeric_columns].copy()\n",
        "    subset_X.fillna(0, inplace=True)\n",
        "    subset_y = subset['Phase'].copy()\n",
        "    global_model.fit(subset_X, subset_y)\n",
        "\n",
        "    # Evaluate the global model on each node's data and store the results\n",
        "    iteration_global_accuracy = []\n",
        "    iteration_global_precision = []\n",
        "\n",
        "    for i in range(num_splits):\n",
        "        split_data = data_splits[i]\n",
        "        X = split_data[numeric_columns].copy()\n",
        "        y = split_data['Phase'].copy()\n",
        "\n",
        "        # Data preprocessing (if necessary)\n",
        "        X.fillna(0, inplace=True)\n",
        "\n",
        "        y_pred = global_model.predict(X)\n",
        "        iteration_global_accuracy.append(accuracy_score(y, y_pred))\n",
        "        iteration_global_precision.append(precision_score(y, y_pred, average='weighted', zero_division=0))\n",
        "\n",
        "    # Store global accuracy and precision for this iteration\n",
        "    global_accuracy_all_iterations.append(iteration_global_accuracy)\n",
        "    global_precision_all_iterations.append(iteration_global_precision)\n",
        "\n",
        "# Organize the results into a DataFrame\n",
        "results_df = pd.DataFrame({\n",
        "    'Global Accuracy': global_accuracy_all_iterations,\n",
        "    'Global Precision': global_precision_all_iterations\n",
        "})\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results_df.to_csv('model_resultsg.csv', index=False)\n",
        "\n",
        "print(\"Results saved to 'model_resultsg.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqtfWWHN4KCw",
        "outputId": "2c5d777e-9c0c-4b94-f732-a7401c9af3d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to 'model_resultsg.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#combined\n",
        "import pandas as pd\n",
        "\n",
        "# Load the results from both CSV files\n",
        "local_results_df = pd.read_csv('model_resultsl.csv')  # Replace with the actual path of the CSV file\n",
        "global_results_df = pd.read_csv('model_resultsg.csv')  # Replace with the actual path of the CSV file\n",
        "\n",
        "# Extract local accuracy and precision from Code 1 results\n",
        "local_accuracy = local_results_df['Local Accuracy'].tolist()\n",
        "local_precision = local_results_df['Local Precision'].tolist()\n",
        "\n",
        "# Extract global accuracy and precision from Code 2 results\n",
        "global_accuracy = global_results_df['Global Accuracy'].tolist()\n",
        "global_precision = global_results_df['Global Precision'].tolist()\n",
        "\n",
        "# Combine the local and global results into a new DataFrame\n",
        "combined_results_df = pd.DataFrame({\n",
        "    'Local Accuracy': local_accuracy,\n",
        "    'Global Accuracy': global_accuracy,\n",
        "    'Local Precision': local_precision,\n",
        "    'Global Precision': global_precision\n",
        "})\n",
        "\n",
        "# Save the combined results to a CSV file\n",
        "combined_results_df.to_csv('model_results_combined.csv', index=False)\n",
        "\n",
        "print(\"Combined results saved to 'model_results_combined.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLVQFWGT5lA9",
        "outputId": "876bc4da-5d5c-4e92-ead6-8e7b64fdf6b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined results saved to 'model_results_combined.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VG8OP5dR6OoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w4hbmqZaJ4Hu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}