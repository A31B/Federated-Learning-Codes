{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucUDaVhudTOh",
        "outputId": "b73bad5f-532f-4772-969c-452754785f90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to 'model_resultsl.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset into a pandas dataframe\n",
        "df = pd.read_csv('ADSXLIST_07Sep2023.csv')\n",
        "\n",
        "# Define the number of iterations and splits\n",
        "num_iterations = 10\n",
        "num_splits = 6\n",
        "\n",
        "# Lists to store accuracy and precision for each iteration\n",
        "local_accuracy_all_iterations = []\n",
        "local_precision_all_iterations = []\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    # Shuffle the data randomly for each iteration\n",
        "    df_shuffled = df.sample(frac=1, random_state=iteration * 123)\n",
        "\n",
        "    # Initial Splitting of the data into sections\n",
        "    split_size = len(df_shuffled) // num_splits\n",
        "    data_splits = [df_shuffled.iloc[i * split_size: (i + 1) * split_size] for i in range(num_splits)]\n",
        "\n",
        "    # Data Shifting: Move 25% data from each node to the next\n",
        "    for i in range(num_splits):\n",
        "        next_index = (i + 1) % num_splits  # Circular shift\n",
        "        data_to_shift = data_splits[i].sample(frac=0.25, random_state=iteration)\n",
        "        data_splits[i] = data_splits[i].drop(data_to_shift.index)\n",
        "        data_splits[next_index] = pd.concat([data_splits[next_index], data_to_shift])\n",
        "\n",
        "    # Lists for storing local accuracy and precision\n",
        "    local_accuracy_iteration = []\n",
        "    local_precision_iteration = []\n",
        "\n",
        "    for i in range(num_splits):\n",
        "        split_data = data_splits[i]\n",
        "\n",
        "        # Filter the 'AXRASH' data for Nodes 1 and 2\n",
        "        if i == 0:  # Node 1\n",
        "            split_data = split_data[split_data['AXRASH'] == 2]\n",
        "            features = ['AXRASH']\n",
        "        elif i == 1:  # Node 2\n",
        "            split_data = split_data[split_data['AXCOUGH'] == 1]\n",
        "            features = ['AXCOUGH']\n",
        "        else:  # Nodes 3 to 6\n",
        "            features = ['AXRASH','AXMUSCLE', 'AXURNFRQ', 'AXENERGY', 'AXDROWSY', 'AXDIZZY', 'AXBREATH','AXCOUGH', 'VISCODE', 'VISCODE2', 'SITEID']\n",
        "\n",
        "        X = split_data[features].copy()\n",
        "        y = split_data['Phase'].copy()\n",
        "\n",
        "        # Data preprocessing steps\n",
        "        # Convert all categorical features using one-hot encoding\n",
        "        if 'VISCODE' in features or 'VISCODE2' in features or 'SITEID' in features:\n",
        "            X = pd.get_dummies(X, columns=['VISCODE', 'VISCODE2', 'SITEID'])\n",
        "\n",
        "        X.fillna(0, inplace=True)\n",
        "\n",
        "        full_features = ['AXRASH', 'AXMUSCLE', 'AXURNFRQ', 'AXENERGY', 'AXDROWSY', 'AXDIZZY', 'AXBREATH','AXCOUGH', 'VISCODE', 'VISCODE2', 'SITEID']\n",
        "        X = X.reindex(columns=full_features, fill_value=0)\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=359)\n",
        "\n",
        "        model = LogisticRegression(max_iter=1000)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        y_pred = model.predict(X_test)\n",
        "        local_accuracy_iteration.append(accuracy_score(y_test, y_pred))\n",
        "        local_precision_iteration.append(precision_score(y_test, y_pred, average='weighted', zero_division=0))\n",
        "\n",
        "    # Store results\n",
        "    local_accuracy_all_iterations.append(local_accuracy_iteration)\n",
        "    local_precision_all_iterations.append(local_precision_iteration)\n",
        "\n",
        "# Display and save the results\n",
        "# Organize the results into a DataFrame\n",
        "results_df = pd.DataFrame({\n",
        "    'Local Accuracy': local_accuracy_all_iterations,\n",
        "    'Local Precision': local_precision_all_iterations\n",
        "})\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results_df.to_csv('model_resultsl.csv', index=False)\n",
        "\n",
        "print(\"Results saved to 'model_resultsl.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset into a pandas dataframe\n",
        "df = pd.read_csv('ADSXLIST_07Sep2023.csv')\n",
        "\n",
        "common_features = ['AXRASH', 'AXMUSCLE', 'AXURNFRQ', 'AXENERGY', 'AXDROWSY', 'AXDIZZY', 'AXBREATH', 'AXCOUGH']\n",
        "\n",
        "# Define categorical features for one-hot encoding\n",
        "categorical_features = ['VISCODE', 'VISCODE2', 'SITEID']\n",
        "df = pd.get_dummies(df, columns=categorical_features)\n",
        "\n",
        "# Exclude any non-numeric columns (e.g., dates or other string columns)\n",
        "numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "# Ensure 'Phase' (target variable) is not in the features list\n",
        "if 'Phase' in numeric_columns:\n",
        "    numeric_columns.remove('Phase')\n",
        "\n",
        "# Define the number of iterations and splits\n",
        "num_iterations = 10\n",
        "num_splits = 6\n",
        "\n",
        "# Lists to store global accuracy and precision for each iteration\n",
        "global_accuracy_all_iterations = []\n",
        "global_precision_all_iterations = []\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "\n",
        "    iteration_global_accuracy = [0] * num_splits\n",
        "    iteration_global_precision = [0] * num_splits\n",
        "\n",
        "    # Shuffle the data randomly for each iteration\n",
        "    df_shuffled = df.sample(frac=1, random_state=iteration * 123)\n",
        "\n",
        "    # Initial Splitting of the data into sections\n",
        "    split_size = len(df_shuffled) // num_splits\n",
        "    data_splits = [df_shuffled.iloc[i * split_size: (i + 1) * split_size] for i in range(num_splits)]\n",
        "\n",
        "    # Data Shifting: Move 25% data from each node to the next\n",
        "    for i in range(num_splits):\n",
        "        next_index = (i + 1) % num_splits\n",
        "        data_to_shift = data_splits[i].sample(frac=0.25, random_state=iteration)\n",
        "        data_splits[i] = data_splits[i].drop(data_to_shift.index)\n",
        "        data_splits[next_index] = pd.concat([data_splits[next_index], data_to_shift])\n",
        "\n",
        "    # Lists for storing model parameters\n",
        "    coefficients_list = []\n",
        "    intercepts_list = []\n",
        "\n",
        "    # Train local models and collect their parameters\n",
        "    for i in range(num_splits):\n",
        "        split_data = data_splits[i]\n",
        "        # Prepare the data for each node\n",
        "        if i == 0:  # Node 1\n",
        "            split_data = split_data[split_data['AXRASH'] == 2]\n",
        "            features = ['AXRASH']\n",
        "        elif i == 1:  # Node 2\n",
        "            split_data = split_data[split_data['AXCOUGH'] == 1]\n",
        "            features = ['AXCOUGH']\n",
        "        else:  # Nodes 3 to 6\n",
        "            features = common_features\n",
        "\n",
        "        X = split_data[numeric_columns].copy()\n",
        "        y = split_data['Phase'].copy()\n",
        "\n",
        "        # Data preprocessing steps\n",
        "        X.fillna(0, inplace=True)\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=359)\n",
        "\n",
        "        model = LogisticRegression(max_iter=1000)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        coefficients_list.append(model.coef_)\n",
        "        intercepts_list.append(model.intercept_)\n",
        "\n",
        "        y_pred = model.predict(X_test)\n",
        "        local_accuracy = accuracy_score(y_test, y_pred)\n",
        "        local_precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    # Federated Averaging: Calculate mean of coefficients and intercepts\n",
        "    avg_coefficients = np.mean(coefficients_list, axis=0)\n",
        "    avg_intercepts = np.mean(intercepts_list, axis=0)\n",
        "\n",
        "    global_model = LogisticRegression(max_iter=1000)\n",
        "    global_model.coef_ = avg_coefficients\n",
        "    global_model.intercept_ = avg_intercepts\n",
        "\n",
        "    # Fit the global model on a small but representative subset of data to initialize 'classes_'\n",
        "    subset = df_shuffled.drop_duplicates(subset='Phase').head(10)\n",
        "    subset_X = subset[numeric_columns].copy()\n",
        "    subset_X.fillna(0, inplace=True)\n",
        "    subset_y = subset['Phase'].copy()\n",
        "    global_model.fit(subset_X, subset_y)\n",
        "\n",
        "    # Sending global model back to all nodes for testing\n",
        "    for i in range(num_splits):\n",
        "        split_data = data_splits[i]\n",
        "        X_test = split_data[numeric_columns].copy()\n",
        "        y_test = split_data['Phase'].copy()\n",
        "\n",
        "        # Data preprocessing (if necessary)\n",
        "        X_test.fillna(0, inplace=True)\n",
        "\n",
        "        y_pred = global_model.predict(X_test)\n",
        "        node_accuracy = accuracy_score(y_test, y_pred)\n",
        "        node_precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "        # Store the results for each node\n",
        "        iteration_global_accuracy[i] = node_accuracy\n",
        "        iteration_global_precision[i] = node_precision\n",
        "\n",
        "    # Store global accuracy and precision for this iteration\n",
        "    global_accuracy_all_iterations.append(iteration_global_accuracy)\n",
        "    global_precision_all_iterations.append(iteration_global_precision)\n",
        "\n",
        "# Organize the results into a DataFrame\n",
        "results_df = pd.DataFrame({\n",
        "    'Global Accuracy': global_accuracy_all_iterations,\n",
        "    'Global Precision': global_precision_all_iterations\n",
        "})\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results_df.to_csv('model_results_global.csv', index=False)\n",
        "\n",
        "print(\"Results saved to 'model_results_global.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMXNlZ9JicPK",
        "outputId": "4aae764d-cb33-4083-fcbf-22a1b2fc1feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to 'model_results_global.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#combined\n",
        "import pandas as pd\n",
        "\n",
        "# Load the results from both CSV files\n",
        "local_results_df = pd.read_csv('model_resultsl.csv')  # Replace with the actual path of the CSV file\n",
        "global_results_df = pd.read_csv('model_resultsg.csv')  # Replace with the actual path of the CSV file\n",
        "\n",
        "# Extract local accuracy and precision from Code 1 results\n",
        "local_accuracy = local_results_df['Local Accuracy'].tolist()\n",
        "local_precision = local_results_df['Local Precision'].tolist()\n",
        "\n",
        "# Extract global accuracy and precision from Code 2 results\n",
        "global_accuracy = global_results_df['Global Accuracy'].tolist()\n",
        "global_precision = global_results_df['Global Precision'].tolist()\n",
        "\n",
        "# Combine the local and global results into a new DataFrame\n",
        "combined_results_df = pd.DataFrame({\n",
        "    'Local Accuracy': local_accuracy,\n",
        "    'Global Accuracy': global_accuracy,\n",
        "    'Local Precision': local_precision,\n",
        "    'Global Precision': global_precision\n",
        "})\n",
        "\n",
        "# Save the combined results to a CSV file\n",
        "combined_results_df.to_csv('model_results_combined.csv', index=False)\n",
        "\n",
        "print(\"Combined results saved to 'model_results_combined.csv'\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caGfJz7CoBI_",
        "outputId": "1016e71f-6e04-40f2-e810-80e3ef696215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined results saved to 'model_results_combined.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('ADSXLIST_07Sep2023.csv')\n",
        "\n",
        "# Define the list of specific features\n",
        "features = ['AXDIARRH', 'AXCONSTP', 'AXABDOMN', 'AXSWEATN' ,'AXNAUSEA',\t'AXVOMIT',\t'AXDIARRH','AXCONSTP'\t,'AXABDOMN','AXSWEATN',\t'AXDIZZY',\t'AXENERGY',\t'AXDROWSY',\t'AXVISION',\t'AXHDACHE',\t'AXDRYMTH',\t'AXBREATH'\t,'AXCOUGH'\t,'AXPALPIT'\t,'AXCHEST','AXURNDIS',\t'AXURNFRQ', 'AXANKLE',\t'AXMUSCLE',\t'AXRASH',\t'AXINSOMN',\t'AXDPMOOD'\t,'AXCRYING'\t,'AXELMOOD']\n",
        "\n",
        "# Iterate through each feature and print value counts\n",
        "for feature in features:\n",
        "    value_counts = df[feature].value_counts()\n",
        "    print(f\"Value counts for '{feature}':\")\n",
        "    print(value_counts)\n",
        "    print()  # Adds a blank line for better readability\n"
      ],
      "metadata": {
        "id": "AC0RXKCJpW1Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}